{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of BERT_Doc_Smelling.ipynb","provenance":[],"collapsed_sections":["EDNFgP87zDq0","PjZeXO-kvNWY","CJI0IkMWxJSn","34SUdPVwu9Mt","116yIIYJuPZ5","ktzxUWTDtCyu"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"MpxvQ14HFYM1","executionInfo":{"status":"ok","timestamp":1603316572467,"user_tz":-360,"elapsed":1241,"user":{"displayName":"Md. Tawkat Islam Khondaker","photoUrl":"","userId":"12040636431562290492"}},"outputId":"75d5965c-887e-4c7b-ad39-236df4f331c6","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jGuiOxBdFh3k"},"source":["!pip install -q keras"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"utYxkMR9F0wq"},"source":["!pip install -q pydrive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OIJwvszjF4AZ"},"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HRjYe1E_DNdu"},"source":["project_path='/content/drive/My Drive/Documentation Smelling/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ollFx-9CU-D"},"source":["!pip install simpletransformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pdPi6dlzJ-Pe"},"source":["import re\n","import string\n","import numpy as np\n","import pandas as pd\n","\n","\n","def clean_text(text):\n","    \n","    text = re.sub(r\"\\n\", \" \", text)\n","    text = re.sub(r\"\\r\", \" \", text)\n","\n","\n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dOkR7D991s_c"},"source":["import pandas as pd\n","\n","df = pd.read_excel(project_path + 'Datasets/dataset.xlsx')\n","\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IeaH7rrAJ8qv"},"source":["#from DataPrep.Clean_Texts import clean_text\n","import pickle\n","#dataset=dataset.head(10)\n","\n","text=df['Documentation Text']\n","text=text.map(lambda x: clean_text(x))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dhLPBSV92jQw"},"source":["label=df.iloc[:,1:6].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oI6rtRZ8DEwp"},"source":["model_type = \"bert\"\n","model_name = \"bert-base-cased\"\n","\n","train_args = {\n","    \"reprocess_input_data\": True,\n","    \"overwrite_output_dir\": True,\n","    \"use_cached_eval_features\": True,\n","    \"output_dir\": project_path + \"Models/Transformers/output/\"+model_type,\n","    \"best_model_dir\": project_path + \"Models/Transformers/output/\"+model_type+\"/best_model\",\n","    \"use_early_stopping\": False,\n","    \"early_stopping_delta\": 0.0,\n","    \"early_stopping_metric\": \"eval_loss\",\n","    \"early_stopping_metric_minimize\" : True,\n","    \"early_stopping_patience\" : 2,\n","    \"evaluate_during_training\": True,\n","    \"max_seq_length\": 512,\n","    \"num_train_epochs\": 10,\n","    \"evaluate_during_training_steps\": 512,\n","    \"wandb_project\": \"Doc Smelling Bert_1\",\n","    \"wandb_kwargs\": {\"name\": model_name},\n","    \"save_model_every_epoch\": False,\n","    \"save_eval_checkpoints\": False,\n","    \"train_batch_size\": 64,\n","    \"eval_batch_size\": 64,\n","    \"evaluate_during_training_verbose\" : True\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DBvFUsR0iDSG"},"source":["\n","\n","!pip install -q iterative-stratification\n","\n","from sklearn.model_selection import train_test_split\n","from simpletransformers.classification import MultiLabelClassificationModel\n","\n","import glob\n","\n","import os\n","#from sklearn.model_selection import KFold\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","import gc\n","import keras.backend as K\n","import numpy as np\n","\n","X_train_all = np.array(text)\n","y_train_all = np.array(label)\n","\n","print(X_train_all.shape)\n","print(y_train_all.shape)\n","\n","num_cross_validation = 5\n","\n","\n","mskf = MultilabelStratifiedKFold(n_splits = num_cross_validation, shuffle=True, random_state=42)\n","pred_list=[]\n","cvscores = []\n","y_true_all_fold = []\n","pred_binary_all_fold = []\n","\n","Fold = 1\n","\n","for train, val in mskf.split(X_train_all, y_train_all):\n","    gc.collect()\n","    K.clear_session()\n","    print('Fold: ', Fold)\n","\n","    X_train = X_train_all[train]\n","    X_val = X_train_all[val]\n","    y_train = y_train_all[train]\n","    y_val = y_train_all[val]\n","\n","    with open(project_path + 'Datasets/Pickle_5_Fold/dataset_' +str(Fold) + '.pickle','wb') as f:\n","        pickle.dump((X_train, X_val, y_train, y_val),f)\n","\n","    Fold = Fold + 1\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UdCSH1b1e86c"},"source":["from sklearn.model_selection import train_test_split\n","from simpletransformers.classification import MultiLabelClassificationModel\n","\n","import pickle\n","import glob\n","\n","import os\n","#from sklearn.model_selection import KFold\n","#from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","import gc\n","import keras.backend as K\n","import numpy as np\n","import pandas as pd\n","\n","\n","num_cross_validation = 5\n","\n","\n","#mskf = MultilabelStratifiedKFold(n_splits = num_cross_validation, shuffle=True, random_state=42)\n","pred_list=[]\n","cvscores = []\n","y_true_all_fold = []\n","pred_binary_all_fold = []\n","\n","Fold = 1\n","\n","#for i in range(num_cross_validation):\n","\n","gc.collect()\n","K.clear_session()\n","print('Fold: ', Fold)\n","\n","with open(project_path + 'Datasets/Pickle_5_Fold/dataset_' +str(Fold) + '.pickle','rb') as f:\n","    X_train, X_val, y_train, y_val = pickle.load(f)\n","\n","\n","\n","ll=[]\n","for i in range(len(X_train)):\n","  ll.append([X_train[i],y_train[i]])\n","\n","train_val_df = pd.DataFrame(ll)\n","train_val_df.columns = [\"text\", \"labels\"]\n","\n","ll=[]\n","for i in range(len(X_val)):\n","  ll.append([X_val[i],y_val[i]])\n","\n","test_df = pd.DataFrame(ll)\n","test_df.columns = [\"text\", \"labels\"]\n","\n","\n","\n","train_df, val_df = train_test_split(train_val_df, test_size=0.1)\n","\n","\n","\n","train_args[\"max_seq_length\"] = 300\n","train_args[\"train_batch_size\"] = 32\n","train_args[\"gradient_accumulation_steps\"] = 2\n","train_args[\"evaluate_during_training\"] = False\n","train_args[\"evaluate_during_training_steps\"] = 25\n","train_args[\"use_early_stopping\"] = False\n","\n","# Create a ClassificationModel\n","model = MultiLabelClassificationModel(model_type, model_name, num_labels=5, args=train_args)\n","\n","# Train the model\n","model.train_model(train_df, eval_df=val_df)\n","\n","pred, raw_outputs = model.predict(test_df['text'])\n","\n","\n","\n","pred_binary=np.array(pred)\n","for i in range(len(pred_binary)):\n","  for j in range(len(pred_binary[i])):\n","    pred_binary[i][j]=int(1*(pred_binary[i][j]>0.5))\n","\n","  y_true_all_fold.append(y_val[i])\n","  pred_binary_all_fold.append(pred_binary[i])\n","\n","with open(project_path + 'Predictions/CV_Bert_1/CV_5_Fold_Predictions/pickle_Pred_doc_Bert_CV_Fold_2_' + str(Fold) +'.pickle','wb') as f:\n","    pickle.dump((y_true_all_fold,pred_binary_all_fold),f)\n","    \n","#Fold = Fold + 1\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3hg57-9cfPEn"},"source":["from itertools import chain\n","import pickle\n","\n","with open(project_path + 'Predictions/CV_Bert_1/CV_5_Fold_Predictions/pickle_Pred_doc_Bert_CV_Fold_2_' + str(1) +'.pickle','rb') as f:\n","  y_test_all, pred_binary_all = pickle.load(f)\n","\n","print(len(y_test_all),len(pred_binary_all))\n","\n","for i in range(2,6):\n","  with open(project_path + 'Predictions/CV_Bert_1/CV_5_Fold_Predictions/pickle_Pred_doc_Bert_CV_Fold_2_' + str(i) +'.pickle','rb') as f:\n","    y_test, pred_binary = pickle.load(f)\n","  \n","  y_test_all=list(chain(y_test_all,y_test))\n","  pred_binary_all=list(chain(pred_binary_all,pred_binary))\n","\n","print(len(y_test_all),len(pred_binary_all))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9HLfsfcsfi_n"},"source":["from sklearn.metrics import classification_report,precision_recall_fscore_support\n","from sklearn.metrics import precision_score,recall_score,f1_score\n","from sklearn.metrics import accuracy_score,jaccard_similarity_score, hamming_loss\n","\n","report=classification_report(y_test,pred_binary)\n","#report=precision_recall_fscore_support(y_test,pred_binary,average='micro')\n","print('Classification Report: '+str(report))\n","\n","\n","precision=precision_score(y_test,pred_binary,average='weighted')\n","print('Weighted Precision: '+str(precision))\n","\n","recall=recall_score(y_test,pred_binary,average='weighted')\n","print('Weighted Recall: '+str(recall))\n","\n","f1=f1_score(y_test,pred_binary,average='weighted')\n","print('Weighted F1 Score: '+str(f1))\n","\n","\n","\n","acc_hard=accuracy_score(y_test,pred_binary)\n","print('Hard Accuracy: '+str(acc_hard))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yM10gYjBfq8P"},"source":["y_true_np = np.array(y_test)\n","y_pred_np = np.array(pred_binary)\n","\n","num_classes = 5\n","for i in range(num_classes):\n","  print('Class: ' + str(i))\n","  new_y_true = y_true_np[:,i]\n","  new_y_pred = y_pred_np[:,i]\n","\n","  print('Accuracy for class ' + str(i) + ': ' + str(accuracy_score(new_y_true,new_y_pred)))\n","  print('Classification Report for class' + str(i) + ': ' + str(classification_report(new_y_true,new_y_pred)))"],"execution_count":null,"outputs":[]}]}